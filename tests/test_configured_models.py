#!/usr/bin/env python3
"""
é…ç½®æ¨¡å‹æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•default.pyä¸­é…ç½®çš„å…·ä½“æ¨¡å‹æ˜¯å¦åœ¨é€†å‘APIä¸­å¯ç”¨
"""

import os
import sys
import requests
import json
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_available_models():
    """è·å–é€†å‘APIä¸­å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    print("ğŸ” è·å–é€†å‘APIå¯ç”¨æ¨¡å‹åˆ—è¡¨...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = os.getenv('OPENAI_BASE_URL', 'https://gptgod.cloud/v1')
    
    if not api_key:
        print("  âŒ OPENAI_API_KEY æœªè®¾ç½®")
        return []
    
    try:
        url = f"{base_url}/models"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            models = data.get('data', [])
            model_ids = [model.get('id', '') for model in models]
            print(f"  âœ… æˆåŠŸè·å– {len(model_ids)} ä¸ªæ¨¡å‹")
            return model_ids
        else:
            print(f"  âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            return []
            
    except Exception as e:
        print(f"  âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def test_specific_model(model_name, available_models):
    """æµ‹è¯•ç‰¹å®šæ¨¡å‹æ˜¯å¦å¯ç”¨"""
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
    if model_name not in available_models:
        print(f"  âŒ æ¨¡å‹ '{model_name}' ä¸åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­")
        
        # å¯»æ‰¾ç›¸ä¼¼çš„æ¨¡å‹å
        similar_models = [m for m in available_models if model_name.lower() in m.lower() or m.lower() in model_name.lower()]
        if similar_models:
            print(f"  ğŸ’¡ æ‰¾åˆ°ç›¸ä¼¼æ¨¡å‹: {similar_models[:3]}")
        return False
    
    # å°è¯•è°ƒç”¨æ¨¡å‹
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = os.getenv('OPENAI_BASE_URL', 'https://gptgod.cloud/v1')
    
    try:
        url = f"{base_url}/chat/completions"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": "è¯·ç®€å•å›ç­”ï¼šä½ å¥½"}
            ],
            "max_tokens": 20,
            "temperature": 0.1
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                print(f"  âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
                print(f"  ğŸ’¬ å“åº”: {content.strip()}")
                return True
            else:
                print(f"  âŒ å“åº”æ ¼å¼å¼‚å¸¸")
                return False
        else:
            print(f"  âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            error_info = response.text[:200]
            print(f"  ğŸ“ é”™è¯¯ä¿¡æ¯: {error_info}")
            return False
            
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ GPT-Researcher é…ç½®æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # ä»default.pyä¸­è¯»å–é…ç½®çš„æ¨¡å‹
    configured_models = {
        "FAST_LLM": "gpt-4o-mini",      # ä» "openai:gpt-4o-mini" æå–
        "SMART_LLM": "gpt-4.1",         # ä» "openai:gpt-4.1" æå–  
        "STRATEGIC_LLM": "o4-mini",     # ä» "openai:o4-mini" æå–
        "O3_LLM": "o3",                 # æ–°å¢ o3 æµ‹è¯•
        "O1_LLM": "o1",                 # æ–°å¢ o1 æµ‹è¯•
    }
    
    print("\nğŸ“‹ é¡¹ç›®ä¸­é…ç½®çš„æ¨¡å‹:")
    for config_name, model_name in configured_models.items():
        print(f"  {config_name}: {model_name}")
    
    print("\n" + "=" * 60)
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models = get_available_models()
    
    if not available_models:
        print("âŒ æ— æ³•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return
    
    # æ˜¾ç¤ºéƒ¨åˆ†å¯ç”¨æ¨¡å‹
    print(f"\nğŸ“Š APIä¸­å¯ç”¨çš„æ¨¡å‹ç¤ºä¾‹ (å…±{len(available_models)}ä¸ª):")
    for i, model in enumerate(available_models[:10]):
        print(f"  {i+1:2d}. {model}")
    if len(available_models) > 10:
        print(f"  ... è¿˜æœ‰ {len(available_models) - 10} ä¸ªæ¨¡å‹")
    
    print("\n" + "=" * 60)
    
    # æµ‹è¯•æ¯ä¸ªé…ç½®çš„æ¨¡å‹
    results = {}
    for config_name, model_name in configured_models.items():
        success = test_specific_model(model_name, available_models)
        results[config_name] = {
            "model": model_name,
            "success": success
        }
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 60)
    
    success_count = 0
    for config_name, result in results.items():
        status = "âœ… å¯ç”¨" if result["success"] else "âŒ ä¸å¯ç”¨"
        print(f"  {config_name:15} | {result['model']:15} | {status}")
        if result["success"]:
            success_count += 1
    
    print("-" * 60)
    print(f"æ€»è®¡: {success_count}/{len(results)} ä¸ªé…ç½®æ¨¡å‹å¯ç”¨")
    
    # ç»™å‡ºå»ºè®®
    if success_count == len(results):
        print("ğŸ‰ æ‰€æœ‰é…ç½®çš„æ¨¡å‹éƒ½å¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
    elif success_count > 0:
        print("âš ï¸  éƒ¨åˆ†æ¨¡å‹å¯ç”¨ï¼Œå»ºè®®:")
        for config_name, result in results.items():
            if not result["success"]:
                print(f"    - æ£€æŸ¥ {config_name} çš„æ¨¡å‹åç§°: {result['model']}")
                # å»ºè®®æ›¿ä»£æ¨¡å‹
                model_name = result['model']
                suggestions = []
                for available in available_models:
                    if 'gpt-4' in available.lower() and 'gpt-4' in model_name.lower():
                        suggestions.append(available)
                    elif 'gpt-3' in available.lower() and 'gpt-3' in model_name.lower():
                        suggestions.append(available)
                    elif model_name.lower() in available.lower():
                        suggestions.append(available)
                
                if suggestions:
                    print(f"      å»ºè®®æ›¿ä»£æ¨¡å‹: {suggestions[:3]}")
    else:
        print("ğŸš¨ æ‰€æœ‰é…ç½®çš„æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. æ£€æŸ¥é€†å‘APIæ˜¯å¦æ”¯æŒè¿™äº›æ¨¡å‹")
        print("  2. æŸ¥çœ‹å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œé€‰æ‹©åˆé€‚çš„æ›¿ä»£æ¨¡å‹")
        print("  3. æ›´æ–° gpt_researcher/config/variables/default.py ä¸­çš„æ¨¡å‹é…ç½®")
    
    print("\nğŸ’¡ å¦‚éœ€ä¿®æ”¹æ¨¡å‹é…ç½®ï¼Œè¯·ç¼–è¾‘æ–‡ä»¶:")
    print("   gpt_researcher/config/variables/default.py")
    print("   ä¿®æ”¹ FAST_LLM, SMART_LLM, STRATEGIC_LLM çš„å€¼")

if __name__ == "__main__":
    main()
