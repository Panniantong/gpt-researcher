"""
ç«å“è°ƒç ” Agent
åŸºäº gpt-researcher çš„ä¸“é—¨ç”¨äºäº§å“ç«å“è°ƒç ”çš„æ™ºèƒ½ä»£ç†
"""
import asyncio
from typing import Dict, List, Any, Optional
from urllib.parse import urlparse
import json

from gpt_researcher import GPTResearcher
from gpt_researcher.config import Config
from gpt_researcher.utils.llm import get_llm
from gpt_researcher.scraper import Scraper
from gpt_researcher.utils.workers import WorkerPool

from .modules.basic_info import BasicInfoExtractor
from .modules.founder_analysis import FounderAnalyzer
from .modules.eight_dimensions import EightDimensionsAnalyzer
from .modules.marketing_intel import MarketingIntelAnalyzer
from .modules.replication_eval import ReplicationEvaluator
from .modules.executive_summary import ExecutiveSummaryGenerator


class CompetitiveIntelligenceAgent:
    """ç«å“è°ƒç ”æ™ºèƒ½ä»£ç†"""
    
    def __init__(
        self,
        query: str = None,
        product_url: str = None,
        llm_provider: str = None,
        model: str = None,
        report_type: str = "competitive_analysis",
        config_path: str = None,
        websocket = None
    ):
        """
        åˆå§‹åŒ–ç«å“è°ƒç ”Agent
        
        Args:
            query: äº§å“åç§°æˆ–æŸ¥è¯¢
            product_url: äº§å“ç½‘å€
            llm_provider: LLMæä¾›å•†
            model: æ¨¡å‹åç§°
            report_type: æŠ¥å‘Šç±»å‹
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            websocket: WebSocketè¿æ¥ï¼ˆç”¨äºå®æ—¶æ›´æ–°ï¼‰
        """
        self.query = query
        self.product_url = product_url
        self.websocket = websocket
        
        # é…ç½®
        self.config = Config(config_path)
        self.llm_provider = llm_provider or self.config.fast_llm_provider
        self.model = model or self.config.fast_llm_model
        
        # åˆå§‹åŒ–å„ä¸ªåˆ†ææ¨¡å—
        self.basic_info_extractor = BasicInfoExtractor(self.llm_provider, self.model)
        self.founder_analyzer = FounderAnalyzer(self.llm_provider, self.model)
        self.eight_dimensions_analyzer = EightDimensionsAnalyzer(self.llm_provider, self.model)
        self.marketing_analyzer = MarketingIntelAnalyzer(self.llm_provider, self.model)
        self.replication_evaluator = ReplicationEvaluator(self.llm_provider, self.model)
        self.summary_generator = ExecutiveSummaryGenerator(self.llm_provider, self.model)
        
        # åˆå§‹åŒ–å·¥ä½œæ± 
        self.worker_pool = WorkerPool(max_workers=5)
        
        # åˆå§‹åŒ–æ£€ç´¢å™¨
        from gpt_researcher.actions.retriever import get_retrievers
        self.retrievers = get_retrievers({}, self.config)
        self._retriever = self.retrievers[0] if self.retrievers else None
        
        # å­˜å‚¨åˆ†æç»“æœ
        self.results = {
            "basic_info": {},
            "founder_analysis": {},
            "eight_dimensions": {},
            "marketing_intel": {},
            "replication_eval": {},
            "executive_summary": {},
            "sources": []
        }
    
    async def run_research(self) -> str:
        """
        è¿è¡Œå®Œæ•´çš„ç«å“è°ƒç ”æµç¨‹
        
        Returns:
            æ ¼å¼åŒ–çš„è°ƒç ”æŠ¥å‘Š
        """
        try:
            # 1. è·å–åŸºç¡€ä¿¡æ¯
            await self._update_status("ğŸ” æ­£åœ¨è·å–äº§å“åŸºç¡€ä¿¡æ¯...")
            await self._extract_basic_info()
            
            # 2. åˆ›å§‹äººèƒŒæ™¯è°ƒç ”
            await self._update_status("ğŸ‘¤ æ­£åœ¨è°ƒç ”åˆ›å§‹äºº/å›¢é˜ŸèƒŒæ™¯...")
            await self._research_founder_background()
            
            # 3. å…«ç»´åˆ†æ
            await self._update_status("ğŸ“Š æ­£åœ¨è¿›è¡Œå…«ç»´æ·±åº¦åˆ†æ...")
            await self._analyze_eight_dimensions()
            
            # 4. è¥é”€æƒ…æŠ¥åˆ†æ
            await self._update_status("ğŸ“ˆ æ­£åœ¨åˆ†æè¥é”€ç­–ç•¥...")
            await self._analyze_marketing_strategy()
            
            # 5. å¤åˆ»éš¾åº¦è¯„ä¼°
            await self._update_status("ğŸ”§ æ­£åœ¨è¯„ä¼°å¤åˆ»éš¾åº¦...")
            await self._evaluate_replication_difficulty()
            
            # 6. ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
            await self._update_status("ğŸ“ æ­£åœ¨ç”Ÿæˆæ‰§è¡Œæ‘˜è¦...")
            await self._generate_executive_summary()
            
            # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            await self._update_status("âœ… æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
            report = self._format_final_report()
            
            return report
            
        except Exception as e:
            await self._update_status(f"âŒ è°ƒç ”è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
            raise
    
    async def _extract_basic_info(self):
        """æå–åŸºç¡€ä¿¡æ¯"""
        if self.product_url:
            # ä»URLè·å–ä¿¡æ¯
            content = await self._scrape_url(self.product_url)
            self.results["basic_info"] = await self.basic_info_extractor.extract_from_content(
                content, 
                self.product_url
            )
        else:
            # ä½¿ç”¨æœç´¢è·å–äº§å“ä¸»é¡µ
            from gpt_researcher.actions.query_processing import get_search_results
            
            # æœç´¢äº§å“å®˜ç½‘
            search_query = f"{self.query} official website"
            if self._retriever:
                search_results = await get_search_results(
                    search_query,
                    self._retriever,
                    researcher=None
                )
                
                if search_results and len(search_results) > 0:
                    # è·å–ç¬¬ä¸€ä¸ªæœç´¢ç»“æœçš„URL
                    self.product_url = search_results[0].get("href", search_results[0].get("url", ""))
                    if self.product_url:
                        content = await self._scrape_url(self.product_url)
                        self.results["basic_info"] = await self.basic_info_extractor.extract_from_content(
                            content,
                            self.product_url
                        )
                    else:
                        # ä½¿ç”¨é»˜è®¤ä¿¡æ¯
                        self.results["basic_info"] = {
                            "name": self.query,
                            "one_liner": "äº§å“æè¿°æœªæ‰¾åˆ°",
                            "type": "æœªçŸ¥",
                            "team_size": "æœªçŸ¥"
                        }
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æœç´¢ç»“æœï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                    self.results["basic_info"] = {
                        "name": self.query,
                        "one_liner": "äº§å“æè¿°æœªæ‰¾åˆ°",
                        "type": "æœªçŸ¥",
                        "team_size": "æœªçŸ¥"
                    }
            else:
                # æ²¡æœ‰æ£€ç´¢å™¨å¯ç”¨
                self.results["basic_info"] = {
                    "name": self.query,
                    "one_liner": "äº§å“æè¿°æœªæ‰¾åˆ°ï¼ˆæ— æœç´¢APIï¼‰",
                    "type": "æœªçŸ¥",
                    "team_size": "æœªçŸ¥"
                }
        
        # éªŒè¯åŸºç¡€ä¿¡æ¯
        self.results["basic_info"] = self.basic_info_extractor.validate_info(
            self.results["basic_info"]
        )
    
    async def _research_founder_background(self):
        """è°ƒç ”åˆ›å§‹äººèƒŒæ™¯"""
        product_name = self.results["basic_info"].get("name", self.query)
        
        # éªŒè¯äº§å“åç§°æ˜¯å¦æœ‰æ•ˆ
        if not product_name or "not found" in product_name.lower() or "âš " in product_name:
            # ä½¿ç”¨åŸå§‹æŸ¥è¯¢è¯
            product_name = self.query
        
        # ç”Ÿæˆæœç´¢æŸ¥è¯¢
        queries = await self.founder_analyzer.generate_search_queries(
            product_name,
            self.product_url
        )
        
        # æ‰§è¡Œæœç´¢
        search_results = await self._perform_searches(queries)
        
        # åˆ†æåˆ›å§‹äººèƒŒæ™¯
        self.results["founder_analysis"] = await self.founder_analyzer.analyze_founder_background(
            product_name,
            search_results
        )
        
        # è¯†åˆ«ç«äº‰ä¼˜åŠ¿
        advantages = self.founder_analyzer.identify_competitive_advantages(
            self.results["founder_analysis"]
        )
        self.results["founder_analysis"]["competitive_advantages"] = advantages
    
    async def _analyze_eight_dimensions(self):
        """è¿›è¡Œå…«ç»´åˆ†æ"""
        product_info = self.results["basic_info"]
        
        # ç”Ÿæˆéœ€è¦ç ”ç©¶çš„ç»´åº¦çš„æŸ¥è¯¢
        dimension_queries = await self.eight_dimensions_analyzer.generate_research_queries(
            product_info
        )
        
        # å¯¹æ¯ä¸ªéœ€è¦ç ”ç©¶çš„ç»´åº¦æ‰§è¡Œæœç´¢
        research_results = {}
        for dimension, queries in dimension_queries.items():
            search_results = await self._perform_searches(queries)
            research_results[dimension] = search_results
        
        # æ‰§è¡Œå…«ç»´åˆ†æ
        self.results["eight_dimensions"] = await self.eight_dimensions_analyzer.analyze_all_dimensions(
            product_info,
            research_results
        )
    
    async def _analyze_marketing_strategy(self):
        """åˆ†æè¥é”€ç­–ç•¥"""
        product_name = self.results["basic_info"].get("name", self.query)
        
        # éªŒè¯äº§å“åç§°æ˜¯å¦æœ‰æ•ˆ
        if not product_name or "not found" in product_name.lower() or "âš " in product_name:
            # ä½¿ç”¨åŸå§‹æŸ¥è¯¢è¯
            product_name = self.query
        
        # ç”Ÿæˆè¥é”€ç›¸å…³æŸ¥è¯¢
        queries = await self.marketing_analyzer.generate_marketing_research_queries(
            product_name,
            self.product_url
        )
        
        # æ‰§è¡Œæœç´¢
        search_results = await self._perform_searches(queries)
        
        # åˆ†æè¥é”€ç­–ç•¥
        self.results["marketing_intel"] = await self.marketing_analyzer.analyze_marketing_strategy(
            product_name,
            search_results
        )
        
        # åˆ†æå†…å®¹ç­–ç•¥
        content_strategy = self.marketing_analyzer.analyze_content_strategy(search_results)
        self.results["marketing_intel"]["content_strategy_analysis"] = content_strategy
    
    async def _evaluate_replication_difficulty(self):
        """è¯„ä¼°å¤åˆ»éš¾åº¦"""
        product_info = self.results["basic_info"]
        
        # è·å–æŠ€æœ¯æ¶æ„ä¿¡æ¯ï¼ˆä»Q8ï¼‰
        tech_architecture = ""
        if "Q8" in self.results["eight_dimensions"]:
            q8_result = self.results["eight_dimensions"]["Q8"]
            if hasattr(q8_result, 'answer'):
                tech_architecture = q8_result.answer
        
        # è·å–åˆ›å§‹äººä¼˜åŠ¿
        founder_advantages = self.results["founder_analysis"].get("unfair_advantages", [])
        
        # è¯„ä¼°å¤åˆ»éš¾åº¦
        self.results["replication_eval"] = await self.replication_evaluator.evaluate_replication_difficulty(
            product_info,
            tech_architecture,
            founder_advantages
        )
        
        # ç”Ÿæˆå¤åˆ»ç­–ç•¥
        strategy = self.replication_evaluator.generate_replication_strategy(
            self.results["replication_eval"],
            product_info
        )
        self.results["replication_eval"]["strategy"] = strategy
    
    async def _generate_executive_summary(self):
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = await self.summary_generator.generate_summary(
            self.results["basic_info"],
            self.results["founder_analysis"],
            self.results["eight_dimensions"],
            self.results["marketing_intel"],
            self.results["replication_eval"]
        )
        
        # ç”Ÿæˆå¯æ‰§è¡Œæ´å¯Ÿ
        insights = self.summary_generator.generate_actionable_insights(
            summary,
            self.results["replication_eval"]
        )
        summary["actionable_insights"] = insights
        
        self.results["executive_summary"] = summary
    
    async def _perform_searches(self, queries: List[str]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæœç´¢æŸ¥è¯¢"""
        from gpt_researcher.actions.query_processing import get_search_results
        
        all_results = []
        
        # ä½¿ç”¨æ£€ç´¢å™¨è¿›è¡Œæœç´¢
        if not self._retriever:
            print("Warning: No retriever available, skipping search")
            return []
        
        for query in queries[:5]:  # é™åˆ¶æŸ¥è¯¢æ•°é‡
            try:
                # è·å–æœç´¢ç»“æœ
                search_results = await get_search_results(
                    query, 
                    self._retriever,
                    researcher=None
                )
                
                # å¤„ç†æœç´¢ç»“æœ
                for result in search_results[:3]:  # æ¯ä¸ªæŸ¥è¯¢é™åˆ¶3ä¸ªç»“æœ
                    url = result.get("href", result.get("url", ""))
                    if url:
                        try:
                            content = await self._scrape_url(url)
                            
                            all_results.append({
                                "query": query,
                                "url": url,
                                "title": result.get("title", self._extract_title(content)),
                                "content": content[:1000]  # é™åˆ¶å†…å®¹é•¿åº¦
                            })
                            
                            # æ·»åŠ åˆ°æºåˆ—è¡¨
                            if url not in self.results["sources"]:
                                self.results["sources"].append(url)
                                
                        except Exception as e:
                            print(f"Error scraping {url}: {e}")
                            # å³ä½¿æŠ“å–å¤±è´¥ï¼Œä¹Ÿä¿å­˜æœç´¢ç»“æœ
                            all_results.append({
                                "query": query,
                                "url": url,
                                "title": result.get("title", ""),
                                "content": result.get("body", "")[:1000]
                            })
                            
            except Exception as e:
                print(f"Error searching for '{query}': {e}")
                continue
        
        return all_results
    
    def _extract_title(self, html_content: str) -> str:
        """ä»HTMLä¸­æå–æ ‡é¢˜"""
        import re
        title_match = re.search(r'<title>(.*?)</title>', html_content, re.IGNORECASE)
        return title_match.group(1) if title_match else "æ— æ ‡é¢˜"
    
    async def _scrape_url(self, url: str, timeout: int = 10) -> str:
        """æŠ“å–å•ä¸ªURLçš„å†…å®¹"""
        try:
            # ä½¿ç”¨è¶…æ—¶æ§åˆ¶
            scraper = Scraper(
                [url], 
                user_agent=self.config.user_agent,
                scraper=self.config.scraper,
                worker_pool=self.worker_pool
            )
            
            # è®¾ç½®è¶…æ—¶
            results = await asyncio.wait_for(
                scraper.run(),
                timeout=timeout
            )
            
            if results and len(results) > 0:
                content = results[0].get('raw_content', '')
                # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯æŠ“å–å¤±è´¥
                if len(content) < 100:
                    print(f"Warning: Content too short for {url}")
                return content
            return ""
        except asyncio.TimeoutError:
            print(f"Timeout scraping {url} after {timeout}s")
            return ""
        except Exception as e:
            print(f"Error scraping {url}: {e}")
            return ""
    
    async def _update_status(self, message: str):
        """æ›´æ–°çŠ¶æ€ï¼ˆé€šè¿‡WebSocketæˆ–æ‰“å°ï¼‰"""
        if self.websocket:
            await self.websocket.send_json({
                "type": "status",
                "message": message
            })
        else:
            print(message)
    
    def _format_final_report(self) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š"""
        report = []
        
        # æ ‡é¢˜
        product_name = self.results["basic_info"].get("name", self.query)
        report.append(f"# ç«å“è°ƒç ”æŠ¥å‘Šï¼š{product_name}")
        report.append("")
        
        # åŸºç¡€ä¿¡æ¯
        report.append("## ã€åŸºç¡€ä¿¡æ¯ | Factsã€‘")
        info = self.results["basic_info"]
        report.append(f"**Team Size**: {info.get('team_size', 'N/A')}")
        report.append(f"**Name**: {info.get('name', 'N/A')}")
        report.append(f"**One-liner**: {info.get('one_liner', 'N/A')}")
        report.append(f"**Type**: {info.get('type', 'N/A')}")
        report.append(f"**URL**: {info.get('url', 'N/A')}")
        report.append(f"**Launch Status**: {info.get('launch_status', 'N/A')}")
        report.append(f"**Founded**: {info.get('founded', 'N/A')}")
        report.append("")
        
        # åˆ›å§‹äºº/å›¢é˜ŸèƒŒæ™¯åˆ†æ
        report.append("## ã€åˆ›å§‹äºº/å›¢é˜ŸèƒŒæ™¯åˆ†æ | Founder Intelligenceã€‘")
        founder = self.results["founder_analysis"]
        
        report.append("### ğŸ‘¤ æ ¸å¿ƒäººç‰©ç”»åƒ")
        profile = founder.get("profile", {})
        report.append(f"- **èº«ä»½èƒŒæ™¯**ï¼š{profile.get('background', 'N/A')}")
        report.append(f"- **æŠ€æœ¯èƒ½åŠ›**ï¼š{profile.get('technical_skills', 'N/A')}")
        report.append(f"- **è¡Œä¸šæ·±åº¦**ï¼š{profile.get('industry_depth', 'N/A')}")
        report.append("")
        
        report.append("### ğŸ¯ ä¸å…¬å¹³ä¼˜åŠ¿è¯†åˆ«")
        advantages = founder.get("unfair_advantages", [])
        for advantage in advantages[:5]:
            report.append(f"- {advantage}")
        report.append("")
        
        report.append("### ğŸ’¡ 'AI + è¡Œä¸šä¸“å®¶' æ¨¡å¼éªŒè¯")
        ai_expert = founder.get("ai_expert_model", {})
        report.append(f"- ç¬¦åˆæ¨¡å¼ï¼š{'æ˜¯' if ai_expert.get('fits_pattern') else 'å¦'}")
        if ai_expert.get("explanation"):
            report.append(f"- è¯´æ˜ï¼š{ai_expert['explanation']}")
        report.append("")
        
        sources = founder.get("sources", [])
        if sources:
            report.append(f"**ä¿¡æ¯æ¥æº**ï¼š{' | '.join(sources[:5])}")
        report.append("")
        
        # å…«ç»´åˆ†æ
        report.append("## ã€å…«ç»´åˆ†æ | 8 Questionsã€‘")
        dimensions = self.results["eight_dimensions"]
        
        for key in sorted(dimensions.keys()):
            analysis = dimensions[key]
            if hasattr(analysis, 'question') and hasattr(analysis, 'answer'):
                report.append(f"### {key} Â· {analysis.question}")
                report.append(analysis.answer)
                if analysis.sources:
                    report.append(f"æ¥æºï¼š{' | '.join(analysis.sources[:3])}")
                report.append("")
        
        # è¥é”€æƒ…æŠ¥
        report.append("## ã€è¥é”€æƒ…æŠ¥ | Growth Intelligenceã€‘")
        marketing = self.results["marketing_intel"]
        
        report.append("### G1 Â· Growth Timeline & Milestones")
        timeline = marketing.get("growth_timeline", {})
        if timeline.get("launch_phase"):
            report.append(f"- **Launch Phase**: {timeline['launch_phase']}")
        if timeline.get("growth_phase"):
            report.append(f"- **Growth Phase**: {timeline['growth_phase']}")
        report.append("")
        
        report.append("### G2 Â· Growth Channels & Tactics")
        channels = marketing.get("growth_channels", {})
        if channels.get("primary_channels"):
            report.append(f"- **Primary Channels**: {', '.join(channels['primary_channels'][:3])}")
        if channels.get("signature_tactics"):
            report.append(f"- **Signature Tactics**: {', '.join(channels['signature_tactics'][:3])}")
        report.append("")
        
        # å¤åˆ»éš¾åº¦è¯„ä¼°
        report.append("## ã€å¤åˆ»éš¾åº¦è¯„ä¼° | Solo Developer Feasibilityã€‘")
        replication = self.results["replication_eval"]
        
        report.append(f"### ğŸ’» AIæ—¶ä»£æŠ€æœ¯å¤åˆ»è¯„ä¼°")
        report.append(f"**éš¾åº¦ç­‰çº§**ï¼š{replication.get('difficulty_level', 'N/A')}")
        report.append("")
        
        report.append("### âš¡ æ ¸å¿ƒæŠ€æœ¯æŒ‘æˆ˜")
        challenges = replication.get("core_challenges", [])
        for i, challenge in enumerate(challenges[:4], 1):
            report.append(f"{i}. {challenge}")
        report.append("")
        
        # æ‰§è¡Œæ‘˜è¦
        report.append("## ã€Executive Summaryã€‘")
        summary = self.results["executive_summary"]
        
        report.append(f"### ğŸ¯ æ ¸å¿ƒæ´å¯Ÿ")
        report.append(summary.get("core_insights", "N/A"))
        report.append("")
        
        report.append(f"### ğŸš€ å¢é•¿æ¨¡å¼")
        report.append(summary.get("growth_model", "N/A"))
        report.append("")
        
        report.append(f"### ğŸ‘‘ åˆ›å§‹äººä¼˜åŠ¿")
        report.append(summary.get("founder_advantages", "N/A"))
        report.append("")
        
        report.append("### ğŸ§© å¯è¿ç§»è¦ç´ ")
        elements = summary.get("transferable_elements", {})
        for category, items in elements.items():
            if items:
                report.append(f"- **{category.capitalize()}**: {items[0] if items else 'N/A'}")
        report.append("")
        
        report.append("### â­ AIæ—¶ä»£ç‹¬ç«‹å¼€å‘è€…ç­–ç•¥")
        report.append(summary.get("indie_developer_strategy", "N/A"))
        report.append("")
        
        # ä¿¡æ¯æ¥æº
        if self.results["sources"]:
            report.append("## ã€ä¿¡æ¯æ¥æºã€‘")
            report.append(f"**Sources**: {' | '.join(self.results['sources'][:10])}")
        
        return "\n".join(report)
    
    async def save_results(self, filepath: str = None):
        """ä¿å­˜è°ƒç ”ç»“æœ"""
        if not filepath:
            product_name = self.results["basic_info"].get("name", self.query)
            filepath = f"competitive_intel_{product_name.replace(' ', '_')}.json"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        await self._update_status(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°ï¼š{filepath}")


# ä¾¿æ·å‡½æ•°
async def analyze_competitor(
    query: str,
    product_url: str = None,
    llm_provider: str = None,
    model: str = None
) -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æç«å“
    
    Args:
        query: äº§å“åç§°æˆ–æŸ¥è¯¢
        product_url: äº§å“ç½‘å€ï¼ˆå¯é€‰ï¼‰
        llm_provider: LLMæä¾›å•†
        model: æ¨¡å‹åç§°
        
    Returns:
        æ ¼å¼åŒ–çš„è°ƒç ”æŠ¥å‘Š
    """
    agent = CompetitiveIntelligenceAgent(
        query=query,
        product_url=product_url,
        llm_provider=llm_provider,
        model=model
    )
    
    return await agent.run_research()