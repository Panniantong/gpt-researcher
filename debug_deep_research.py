#!/usr/bin/env python3
"""
è°ƒè¯•Deep Researchä¸­çš„embeddingé—®é¢˜
"""

import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_embedding_in_context():
    """æµ‹è¯•åœ¨ä¸Šä¸‹æ–‡å‹ç¼©ä¸­çš„embeddingé—®é¢˜"""
    print("ğŸ” æµ‹è¯•Deep Researchä¸­çš„embeddingé—®é¢˜...")
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    try:
        from gpt_researcher.memory.embeddings import Memory
        from gpt_researcher.context.compression import ContextCompressor
        from gpt_researcher.config.config import Config
        
        # åˆ›å»ºé…ç½®
        cfg = Config()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   Embedding Provider: {cfg.embedding_provider}")
        print(f"   Embedding Model: {cfg.embedding_model}")
        
        # åˆ›å»ºMemoryå®ä¾‹
        memory = Memory(cfg.embedding_provider, cfg.embedding_model, **cfg.embedding_kwargs)
        print(f"âœ… Memoryå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # è·å–embeddings
        embeddings = memory.get_embeddings()
        print(f"âœ… Embeddingsè·å–æˆåŠŸ: {type(embeddings)}")
        
        # æµ‹è¯•ç®€å•çš„embedding
        test_text = "This is a test document for embedding."
        try:
            result = embeddings.embed_query(test_text)
            print(f"âœ… å•ä¸ªæŸ¥è¯¢embeddingæˆåŠŸ:")
            print(f"   ç±»å‹: {type(result)}")
            print(f"   é•¿åº¦: {len(result) if hasattr(result, '__len__') else 'N/A'}")
            if isinstance(result, list) and len(result) > 0:
                print(f"   å‰5ä¸ªå€¼: {result[:5]}")
        except Exception as e:
            print(f"âŒ å•ä¸ªæŸ¥è¯¢embeddingå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æ¨¡æ‹Ÿæœç´¢ç»“æœæ•°æ®
        mock_documents = [
            {
                "title": "Test Document 1",
                "body": "This is the first test document with some content about artificial intelligence and machine learning.",
                "href": "https://example.com/doc1"
            },
            {
                "title": "Test Document 2", 
                "body": "This is the second test document discussing natural language processing and deep learning techniques.",
                "href": "https://example.com/doc2"
            },
            {
                "title": "Test Document 3",
                "body": "The third document covers computer vision and neural networks in detail.",
                "href": "https://example.com/doc3"
            }
        ]
        
        print(f"\nğŸ“š æµ‹è¯•ä¸Šä¸‹æ–‡å‹ç¼©ï¼Œæ–‡æ¡£æ•°é‡: {len(mock_documents)}")
        
        # åˆ›å»ºContextCompressor
        try:
            context_compressor = ContextCompressor(
                documents=mock_documents,
                embeddings=embeddings,
                prompt_family=None  # ç®€åŒ–æµ‹è¯•
            )
            print(f"âœ… ContextCompressoråˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âŒ ContextCompressoråˆ›å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡è·å–
        test_query = "artificial intelligence and machine learning"
        try:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{test_query}'")
            context = await context_compressor.async_get_context(test_query, max_results=3)
            
            print(f"âœ… ä¸Šä¸‹æ–‡è·å–æˆåŠŸ:")
            print(f"   ç±»å‹: {type(context)}")
            print(f"   é•¿åº¦: {len(context) if hasattr(context, '__len__') else 'N/A'}")
            
            if context:
                if isinstance(context, str):
                    print(f"   å†…å®¹é¢„è§ˆ: {context[:200]}...")
                elif isinstance(context, list):
                    print(f"   åˆ—è¡¨é•¿åº¦: {len(context)}")
                    for i, item in enumerate(context[:2]):
                        print(f"   é¡¹ç›® {i+1}: {str(item)[:100]}...")
            else:
                print("   âš ï¸ è¿”å›çš„ä¸Šä¸‹æ–‡ä¸ºç©º")
                
        except Exception as e:
            print(f"âŒ ä¸Šä¸‹æ–‡è·å–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯embeddingç›¸å…³çš„é”™è¯¯
            error_str = str(e).lower()
            if 'embedding' in error_str or 'none' in error_str:
                print("\nğŸ”§ è¿™çœ‹èµ·æ¥æ˜¯embeddingç›¸å…³çš„é”™è¯¯")
                print("   å¯èƒ½çš„åŸå› :")
                print("   1. APIå¯†é’¥æˆ–base_urlé…ç½®é—®é¢˜")
                print("   2. é€†å‘APIä¸æ”¯æŒembeddingæ¥å£")
                print("   3. APIå“åº”æ ¼å¼ä¸åŒ¹é…")
                
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

async def test_simple_deep_research():
    """æµ‹è¯•ç®€åŒ–çš„Deep Researchæµç¨‹"""
    print("\nğŸš€ æµ‹è¯•ç®€åŒ–çš„Deep Researchæµç¨‹...")
    
    try:
        from gpt_researcher.agent import GPTResearcher
        
        # åˆ›å»ºç ”ç©¶å‘˜å®ä¾‹
        researcher = GPTResearcher(
            query="What is artificial intelligence?",
            report_type="research_report",
            verbose=True
        )
        
        print(f"âœ… GPTResearcherå®ä¾‹åˆ›å»ºæˆåŠŸ")
        print(f"   æŸ¥è¯¢: {researcher.query}")
        print(f"   æŠ¥å‘Šç±»å‹: {researcher.report_type}")
        
        # æµ‹è¯•Deep Research
        from gpt_researcher.skills.deep_research import DeepResearchSkill
        
        deep_research = DeepResearchSkill(researcher)
        print(f"âœ… DeepResearchSkillå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # åªæµ‹è¯•ç ”ç©¶è®¡åˆ’ç”Ÿæˆï¼Œä¸æ‰§è¡Œå®Œæ•´ç ”ç©¶
        try:
            research_plan = await deep_research.generate_research_plan(researcher.query, num_questions=2)
            print(f"âœ… ç ”ç©¶è®¡åˆ’ç”ŸæˆæˆåŠŸ:")
            for i, question in enumerate(research_plan, 1):
                print(f"   {i}. {question}")
        except Exception as e:
            print(f"âŒ ç ”ç©¶è®¡åˆ’ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ Deep Researchæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è°ƒè¯•Deep Researchä¸­çš„embeddingé—®é¢˜...")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_embedding_in_context())
    asyncio.run(test_simple_deep_research())
    
    print("\nâœ… è°ƒè¯•å®Œæˆ")
